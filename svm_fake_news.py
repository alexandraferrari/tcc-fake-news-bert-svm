# -*- coding: utf-8 -*-
"""SVM_fake-news.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yRZ-0qBHEd0N5bcXxkyx28zQ7x5bkj_T

Script desenvolvido para o Trabalho de Conclusão de Curso "COMPARAÇÃO DE TÉCNICAS DE MACHINE LEARNING PARA DETECÇÃO DE NOTÍCIAS
FALSAS EM TEXTOS EM PORTUGUÊS" do curso de Especialização em Inteligência Artificial Aplicada, da Universidade Federal do Paraná.
Autora: Alexandra Ferrari

Etapas para configuração, treinamento e teste do modelo SVM para classificação de notícias.
"""

nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')
nltk.download('punkt_tab')

import matplotlib.pyplot as plt
import nltk
import numpy as np
import pandas as pd
import re
import seaborn as sns
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.svm import SVC

np.random.seed(500)

dataset = pd.read_csv('./news_br_corpus.csv', encoding="latin1")

dataset.head()

dataset.drop(['index'],inplace=True,axis=1)

dataset.head()

import random
for i in range(1,10):
    random_ind = random.randint(0,len(dataset))
    print(str(dataset["preprocessed_news"][random_ind]),end="\nLabel: ")
    print(str(dataset["label"][random_ind]),end="\n\n")

dataset['label'].value_counts()

dataset['label'] = [1 if i == 'fake' else 0 for i in dataset['label']]
dataset.head()

fakeFD = nltk.FreqDist(word for text in dataset[dataset['label'] == 1]['preprocessed_news'] for word in text.split())
trueFD = nltk.FreqDist(word for text in dataset[dataset['label'] == 0]['preprocessed_news'] for word in text.split())

"""Frequência de palavras mais comuns nas notícias verdadeiras"""

trueFD.most_common(20)

plt.subplots(figsize=(8,6))
plt.title("Palavras mais usadas nas notícias falsas")
fakeFD.plot(50)
plt.show()


cleanedData = []

lemma = WordNetLemmatizer()
swords = stopwords.words("portuguese")
swords.append('r') #removendo caractere r (R$)


for text in dataset["preprocessed_news"]:
    # removendo links
    text = re.sub(r'http\S+', '', text)

    # removendo tudo, exceto caracteres alfanuméricos
    text = re.sub("[^a-zA-Z0-9]"," ",text)

    # Tokenizing and lemmatizing
    text = nltk.word_tokenize(text.lower())
    text = [lemma.lemmatize(word) for word in text]

    # removendo stopwords
    text = [word for word in text if word not in swords]

    text = " ".join(text)

    cleanedData.append(text)

for i in range(0,5):
    print(cleanedData[i],end="\n\n")

vectorizer = CountVectorizer(max_features=10000)
BOW = vectorizer.fit_transform(cleanedData)

#vectorizer.get_feature_names_out()

x_train,x_test,y_train,y_test = train_test_split(BOW,np.asarray(dataset["label"]), random_state=50)

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

"""**SVM** classifier"""

# 27m46s

fine_tuning_parameters =  [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-5, 'scale', 'auto'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},
                     {'kernel': ['sigmoid'], 'gamma': [1e-2, 1e-5, 'scale', 'auto'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] },
                     {'kernel': ['linear'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}]

model = GridSearchCV(SVC(), fine_tuning_parameters, cv=2, scoring='accuracy')
model.fit(x_train, y_train)

predictions = model.predict(x_test)

results = pd.DataFrame(model.cv_results_)
top_3 = results.nlargest(3, 'mean_test_score')  # Separando os 3 melhores pela acurácia

# Calculando métricas
acuracia = accuracy_score(y_test, predictions)
precisao = precision_score(y_test, predictions)  # Para classe positiva (1)
sensibilidade = recall_score(y_test, predictions)  # Também chamado de recall
f1 = f1_score(y_test, predictions)

print("Melhores parâmetros:", model.best_params_)

print("Top 3 melhores configurações:")
print(top_3[['params', 'mean_test_score']])

# Exibindo os resultados do conjunto com maior acurácia
print(f"Acurácia: {acuracia:.5f}")
print(f"Precisão: {precisao:.5f}")
print(f"Sensibilidade (Recall): {sensibilidade:.5f}")
print(f"Medida F1: {f1:.5f}")

top3 = results.sort_values(by='mean_test_score', ascending=False).head(3)

for idx, row in top3.iterrows():
    params = row['params']
    model = SVC(**params)
    model.fit(x_train, y_train)
    predictions = model.predict(x_test)


    acuracia = accuracy_score(y_test, predictions)
    precisao = precision_score(y_test, predictions)
    sensibilidade = recall_score(y_test, predictions)
    f1 = f1_score(y_test, predictions)

    print(f"Parâmetros: {params}")
    print(f"Acurácia: {acuracia:.5f}")
    print(f"Precisão: {precisao:.5f}")
    print(f"Sensibilidade (Recall): {sensibilidade:.5f}")
    print(f"Medida F1: {f1:.5f}")
    print("-" * 40)

labels = np.unique(y_test)  # Obtém as classes únicas
cm = confusion_matrix(y_test, predictions, labels=labels)

# Visualizando a matriz de confusão
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=labels, yticklabels=labels)
plt.title("Matriz de Confusão")
plt.xlabel("Predito")
plt.ylabel("Real")
plt.show()
