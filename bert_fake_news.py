"""BERT_fake-news.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/138W7VbcH4YEhVMN1tlfwOExRyg91szSL

Script desenvolvido para o Trabalho de Conclusão de Curso "COMPARAÇÃO DE TÉCNICAS DE MACHINE LEARNING PARA DETECÇÃO DE NOTÍCIAS
FALSAS EM TEXTOS EM PORTUGUÊS" do curso de Especialização em Inteligência Artificial Aplicada, da Universidade Federal do Paraná.
Autora: Alexandra Ferrari

Etapas para configuração, treinamento e teste do modelo BERT para classificação de notícias.
"""

import datetime
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import random
import seaborn as sns
import time
import torch

from collections import Counter
from statistics import mean
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler, Subset
from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup

seed = 524375

random.seed(seed)
np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed_all(seed)

df = pd.read_csv("news_br_corpus.csv", index_col=0)

df.info()
df.head()

df.groupby('label').size()

# Declarando o tokenizador bert-base-uncased
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 2, output_attentions = False, output_hidden_states = False)

df['label'] = [1 if i == 'fake' else 0 for i in df['label']]
df.head()

# Tokeniza todas as sentenças utilizando o método wordpiece
input_ids = []
attention_masks = []

for sentence in df['preprocessed_news'].values:
    encoded_dict = tokenizer.encode_plus(
                        sentence,
                        add_special_tokens = True,  # adicionando os tokens [CLS] e [SEP]
                        max_length = 64,  # sentenças com mais de 64 tokens são truncadas e sentenças menores são preenchidas com o token [PAD]
                        truncation=True,  # Para usar o truncamento
                        padding='max_length',  # Para incluir o token '[PAD]' se necessário
                        return_attention_mask = True,  # Retorna a lista de atenção, que é 1 em na posição em que o token não for [PAD] e é 0 quando o token for [PAD]
                        return_tensors = 'pt'  # Retorna as listas como objeto do tipo tensor
                   )

    input_ids.append(encoded_dict['input_ids'])
    attention_masks.append(encoded_dict['attention_mask'])


input_ids = torch.cat(input_ids, dim=0)
attention_masks = torch.cat(attention_masks, dim=0)
labels = torch.tensor(df['label'].values)

# print('Sentença original: ', df['preprocessed_news'].values[0])
# print('Sentença tokenizada: ', input_ids[0])
# print('Atenção: ', attention_masks[0])
# print('Label: ', labels[0])

# Combinando as listas obtidas na fase de tokenização para criar um objeto TensorDataset
dataset = TensorDataset(input_ids, attention_masks, labels)

# Calculando o número de sentenças que cada conjunto precisa ter para seguir a proporção 80-10-10
train_size = int(0.8 * len(dataset))
val_size = int(0.1 * len(dataset))
test_size = len(dataset) - train_size - val_size

# Dividindo os conjuntos aleatoriamente de acordo com o tamanho amostral calculado
train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

print('{:>5,} sentenças para treinamento'.format(train_size))
print('{:>5,} sentenças para validação'.format(val_size))
print('{:>5,} sentenças para teste'.format(test_size))

# Hiperparâmetros
batch_size = 32
learning_rate = 3e-5
epochs = 5

# separando os conjuntos com tamanho do batch = 32
train_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size = batch_size)
validation_dataloader = DataLoader(val_dataset, sampler = SequentialSampler(val_dataset), batch_size = batch_size)
prediction_dataloader = DataLoader(test_dataset, sampler = SequentialSampler(test_dataset), batch_size = batch_size)

# Otimizador AdamW => é o objeto responsável por realizar a atualização dos parâmetros do modelo
optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)

# Cria o objeto responsável por diminuir a taxa de aprendizagem na medida em que o modelo aprende
# O 'num_training_steps' é calculado como o número de lotes multiplicado pelo número de épocas
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = len(train_dataloader) * epochs)

def flat_accuracy(preds, labels):
    pred_flat = np.argmax(preds, axis=1).flatten()
    labels_flat = labels.flatten()
    return np.sum(pred_flat == labels_flat) / len(labels_flat)

def format_time(elapsed):
    elapsed_rounded = int(round((elapsed)))

    return str(datetime.timedelta(seconds=elapsed_rounded))

training_stats = []

initial_time = time.time()
device = torch.device("cpu")

for epoch_i in range(0, epochs):
    print('\n======== Epoca {:} / {:} ========'.format(epoch_i + 1, epochs))
    print('Treinando...')

    t0 = time.time()  # Mede o tempo de treinamento desta época
    total_train_accuracy = 0  # Reinicia a acurácia total para esta época
    total_train_loss = 0  # Reinicia a perda total para esta época

    model.train()

    for step, batch in enumerate(train_dataloader):
        if step % 40 == 0 and not step == 0:
            print('  Lote {:>5,}  de  {:>5,}.    Tempo decorrido: {:}.'.format(step, len(train_dataloader), format_time(time.time() - t0)))

        # 'batch' é um objeto que contém 3 tensores:
        #   [0]: input_ids
        #   [1]: attention_masks
        #   [2]: labels
        b_input_ids = batch[0].to(device)
        b_input_mask = batch[1].to(device)
        b_labels = batch[2].to(device)

        model.zero_grad()

        result = model(b_input_ids,
                       token_type_ids=None,
                       attention_mask=b_input_mask,
                       labels=b_labels,
                       return_dict=True)

        loss = result.loss  # Perda de classificação
        logits = result.logits  # Para cada sentença, o label com o maior escore será aquele que o modelo escolherá como o label verdadeiro da sentença

        total_train_loss += loss.item()  # Acumulando o erro de treinamento em todos os lotes para que possamos calcular a perda média ao final

        # Movendo os logits e labels para a CPU
        logits = logits.detach().cpu().numpy()
        label_ids = b_labels.to('cpu').numpy()

        total_train_accuracy += flat_accuracy(logits, label_ids)  # Acumula a acuracia de treinamento

        loss.backward()  # Executa o método backward para calcular os gradientes

        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)

        optimizer.step()  # Atualiza os parâmetros do modelo e executa um passo utilizando o gradiente computado

        scheduler.step()  # Atualiza a taxa de aprendizado

    avg_train_accuracy = total_train_accuracy / len(train_dataloader)  # Calcula a acurácia média de treinamento
    print("  Acuracia: {0:.2f}".format(avg_train_accuracy))

    avg_train_loss = total_train_loss / len(train_dataloader)  # Calcula a perda média dos lotes

    training_time = format_time(time.time() - t0)

    print("  Perda media de treinamento: {0:.2f}".format(avg_train_loss))
    print("  Treinamento da epoca levou: {:}".format(training_time))

    print("\nValidando...")

    t0 = time.time()

    model.eval()  # Coloca o modelo em modo de validação

    total_eval_accuracy = 0
    total_eval_loss = 0

    for batch in validation_dataloader:
        b_input_ids = batch[0].to(device)
        b_input_mask = batch[1].to(device)
        b_labels = batch[2].to(device)

        with torch.no_grad():
            result = model(b_input_ids,
                           token_type_ids=None,
                           attention_mask=b_input_mask,
                           labels=b_labels,
                           return_dict=True)

        loss = result.loss
        logits = result.logits

        total_eval_loss += loss.item() # soma da perda de validação

        logits = logits.detach().cpu().numpy()
        label_ids = b_labels.to('cpu').numpy()

        total_eval_accuracy += flat_accuracy(logits, label_ids)  # soma da acurácia de validação


    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader) #acurácia média
    print("  Acuracia: {0:.2f}".format(avg_val_accuracy))

    avg_val_loss = total_eval_loss / len(validation_dataloader) # perda média

    validation_time = format_time(time.time() - t0)

    print("  Perda de validacao: {0:.2f}".format(avg_val_loss))
    print("  Validacao levou: {:}".format(validation_time))

    training_stats.append(
        {
            'epoca': epoch_i + 1,
            'Perda de treinamento': avg_train_loss,
            'Perda de validacao': avg_val_loss,
            'Acuracia de treinamento': avg_train_accuracy,
            'Acuracia de validacao': avg_val_accuracy,
            'Tempo de treinamento': training_time,
            'Tempo de validacao': validation_time
        }
    )

print("\nTreinamento concluído!")
print("Tempo total de treinamento: {:} (hh:mm:ss)".format(format_time(time.time()-initial_time)))

# Define o modelo para o modo de validação
model.eval()

predictions = []
true_labels = []

for batch in prediction_dataloader:
  b_input_ids = batch[0].to(device)
  b_input_mask = batch[1].to(device)
  b_labels = batch[2].to(device)

  with torch.no_grad():
    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)

  logits = outputs[0]
  logits = logits.detach().cpu().numpy()
  label_ids = b_labels.to('cpu').numpy()

  predictions.append(logits)
  true_labels.append(label_ids)

flat_predictions = np.concatenate(predictions, axis=0)
flat_predictions = np.argmax(flat_predictions, axis=1).flatten()
flat_true_labels = np.concatenate(true_labels, axis=0).flatten()

# computa a matriz de confusão
cm = confusion_matrix(flat_true_labels, flat_predictions)

# plota a matriz de confusão
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['0', '1'], yticklabels=['0', '1'])
plt.xlabel('Predito')
plt.ylabel('Real')
plt.title('Matriz de Confusão')
plt.show()

# Calculando métricas
acuracia = accuracy_score(flat_true_labels, flat_predictions)
precisao = precision_score(flat_true_labels, flat_predictions)
sensibilidade = recall_score(flat_true_labels, flat_predictions)
f1 = f1_score(flat_true_labels, flat_predictions)

# Exibindo os resultados
print(f"Acurácia: {acuracia:.5f}")
print(f"Precisão: {precisao:.5f}")
print(f"Sensibilidade (Recall): {sensibilidade:.5f}")
print(f"Medida F1: {f1:.5f}")